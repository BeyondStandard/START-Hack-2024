version: 2
project: start

options:
    skipBinaries: true

    gptModel:
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-instruct
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4-1106-vision-preview
        - gpt-4
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0613

    embeddingModel:
        - text-embedding-3-small
        - text-embedding-ada-002
        - text-embedding-3-large
    
    voice:
        - Matilda
        - Rachel
        - Drew
        - Clyde
        - Paul
        - Domi
        - Dave
        - Fin
        - Sarah
        - Antoni
        - Thomas
        - Charlie
        - George
        - Emily
        - Elli
        - Callum
        - Patrick
        - Harry
        - Liam
        - Dorothy
        - Josh
        - Arnold
        - Charlotte
        - Alice
        - Matthew
        - James
        - Joseph
        - Jeremy
        - Michael
        - Ethan
        - Chris
        - Gigi
        - Freya
        - Brian
        - Grace
        - Daniel
        - Lily
        - Serena
        - Adam
        - Nicole
        - Bill
        - Jessie
        - Sam
        - Glinda
        - Giovanni
        - Mimi

import:
    - scripts/grml.sh

commands:
    setup:
        help: setup the project
        exec: |
            python3 -m venv .venv
            source .venv/bin/activate
            pip install poetry
            poetry install --no-root
            sh scripts/api.sh
            
            skipBinaries
            wget -q --show-progress -P data https://djstarthackathon.blob.core.windows.net/data/data.zip
            unzip data/data.zip -d data
            rm data/data.zip
            

        commands:
            windows:
                help: setup the project for windows
                exec: |
                    conda env create -f environment.yml

    launch:
        help: launcher commands
        commands:
            backend:
                help: launch the backend
                exec: |
                    source .venv/bin/activate
                    uvicorn backend.app:app --reload --port 8000
                commands:
                    windows:
                        help: setup for windows
                        exec: |
                            conda activate st_gallen_env
                            uvicorn backend.app:app --reload --port 8000

    tokenize:
        help: tokenize the data
        commands:
            pickle:
                help: pickle the html data
                exec: |
                    source .venv/bin/activate
                    python3 tokenizer/pickle_data.py

    ask:
        help: ask the server a question
        args:
            - query
        exec: |
            curl -X POST -H "Content-Type: application/json" -d '{"content": "'"${query}"'"}' http://localhost:8000/chat
